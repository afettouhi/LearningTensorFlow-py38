{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Import MNIST data\n",
    "import tensorflow_datasets as tfds\n",
    "mnist = tfds.load(name='mnist', split=['train', 'test'], data_dir=\"../data/\")\n",
    "\n",
    "# Define some parameters\n",
    "element_size = 28\n",
    "time_steps = 28\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# Where to save TensorBoard model summaries\n",
    "LOG_DIR = \"../data/logs/RNN_with_summaries\"\n",
    "\n",
    "# Create placeholders for inputs, labels\n",
    "_inputs = tf.compat.v1.placeholder(tf.float32,shape=[None, time_steps,\n",
    "                                              element_size],\n",
    "                                              name='inputs')\n",
    "y = tf.compat.v1.placeholder(tf.float32, shape=[None, num_classes],\n",
    "                                              name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-f35ac68fb51d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mbatch_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_y\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmnist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;31m# Reshape data to get 28 sequences of 28 pixels\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mbatch_x\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch_x\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime_steps\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0melement_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "batch_x, batch_y = mnist(batch_size)\n",
    "# Reshape data to get 28 sequences of 28 pixels\n",
    "batch_x = batch_x.reshape((batch_size, time_steps, element_size))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# This helper function, taken from the official TensorFlow documentation,\n",
    "# simply adds some ops that take care of logging summaries\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "      mean = tf.reduce_mean(var)\n",
    "      tf.summary.scalar('mean', mean)\n",
    "      with tf.name_scope('stddev'):\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "      tf.summary.scalar('stddev', stddev)\n",
    "      tf.summary.scalar('max', tf.reduce_max(var))\n",
    "      tf.summary.scalar('min', tf.reduce_min(var))\n",
    "      tf.summary.histogram('histogram', var)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Weights and bias for input and hidden layer\n",
    "with tf.name_scope('rnn_weights'):\n",
    "    with tf.name_scope(\"W_x\"):\n",
    "        Wx = tf.Variable(tf.zeros([element_size, hidden_layer_size]))\n",
    "        variable_summaries(Wx)\n",
    "    with tf.name_scope(\"W_h\"):\n",
    "        Wh = tf.Variable(tf.zeros([hidden_layer_size, hidden_layer_size]))\n",
    "        variable_summaries(Wh)\n",
    "    with tf.name_scope(\"Bias\"):\n",
    "        b_rnn = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "        variable_summaries(b_rnn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def rnn_step(previous_hidden_state,x):\n",
    "\n",
    "        current_hidden_state = tf.tanh(\n",
    "            tf.matmul(previous_hidden_state, Wh) +\n",
    "            tf.matmul(x, Wx) + b_rnn)\n",
    "\n",
    "        return current_hidden_state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Current input shape: (batch_size, time_steps, element_size)\n",
    "processed_input = tf.transpose(_inputs, perm=[1, 0, 2])\n",
    "# Current input shape now: (time_steps, batch_size, element_size)\n",
    "\n",
    "initial_hidden = tf.zeros([batch_size,hidden_layer_size])\n",
    "# Getting all state vectors across time\n",
    "all_hidden_states = tf.scan(rnn_step,\n",
    "                            processed_input,\n",
    "                            initializer=initial_hidden,\n",
    "                            name='states')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([b'T', b'Te', b'Ten', b'Tens', b'Tenso', b'Tensor', b'Tensor ',\n       b'Tensor F', b'Tensor Fl', b'Tensor Flo', b'Tensor Flow'],\n      dtype=object)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "elems = np.array([\"T\",\"e\",\"n\",\"s\",\"o\",\"r\", \" \", \"F\",\"l\",\"o\",\"w\"])\n",
    "scan_sum = tf.scan(lambda a, x: a + x, elems)\n",
    "\n",
    "sess=tf.compat.v1.InteractiveSession()\n",
    "sess.run(scan_sum)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Weights for output layers\n",
    "with tf.name_scope('linear_layer_weights') as scope:\n",
    "    with tf.name_scope(\"W_linear\"):\n",
    "        Wl = tf.Variable(tf.compat.v1.truncated_normal([hidden_layer_size,\n",
    "                                              num_classes],\n",
    "                                              mean=0,stddev=.01))\n",
    "        variable_summaries(Wl)\n",
    "    with tf.name_scope(\"Bias_linear\"):\n",
    "        bl = tf.Variable(tf.compat.v1.truncated_normal([num_classes],\n",
    "                                             mean=0,stddev=.01))\n",
    "        variable_summaries(bl)\n",
    "\n",
    "# Apply linear layer to state vector\n",
    "def get_linear_layer(hidden_state):\n",
    "\n",
    "    return tf.matmul(hidden_state, Wl) + bl\n",
    "\n",
    "with tf.name_scope('linear_layer_weights') as scope:\n",
    "    # Iterate across time, apply linear layer to all RNN outputs\n",
    "    all_outputs = tf.map_fn(get_linear_layer, all_hidden_states)\n",
    "    # Get last output\n",
    "    output = all_outputs[-1]\n",
    "    tf.summary.histogram('outputs', output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "   tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y))\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    # Using RMSPropOptimizer\n",
    "    train_step = tf.compat.v1.train.RMSPropOptimizer(0.001, 0.9)\\\n",
    "                                   .minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(\n",
    "                                tf.argmax(y,1), tf.argmax(output,1))\n",
    "\n",
    "    accuracy = (tf.reduce_mean(\n",
    "                       tf.cast(correct_prediction, tf.float32)))*100\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all the summaries\n",
    "merged = tf.compat.v1.summary.merge_all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-c0f4335c6654>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Get a small test set\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m test_data = mnist.reshape((-1, time_steps,\n\u001B[0m\u001B[1;32m      3\u001B[0m                                                      element_size))\n\u001B[1;32m      4\u001B[0m \u001B[0mtest_label\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmnist\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# Get a small test set\n",
    "test_data = mnist.reshape((-1, time_steps,\n",
    "                                                     element_size))\n",
    "test_label = mnist.labels[:batch_size]\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    # Write summaries to LOG_DIR -- used by TensorBoard\n",
    "    train_writer = tf.compat.v1.summary.FileWriter(LOG_DIR + '/train',\n",
    "                                         graph=tf.compat.v1.get_default_graph())\n",
    "    test_writer = tf.compat.v1.summary.FileWriter(LOG_DIR + '/test',\n",
    "                                        graph=tf.compat.v1.get_default_graph())\n",
    "\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "    for i in range(10000):\n",
    "\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Reshape data to get 28 sequences of 28 pixels\n",
    "            batch_x = batch_x.reshape((batch_size, time_steps,\n",
    "                                       element_size))\n",
    "            summary,_ = sess.run([merged,train_step],\n",
    "                                feed_dict={_inputs:batch_x, y:batch_y})\n",
    "            # Add to summaries\n",
    "            train_writer.add_summary(summary, i)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                acc,loss, = sess.run([accuracy,cross_entropy],\n",
    "                                     feed_dict={_inputs: batch_x,\n",
    "                                                y: batch_y})\n",
    "                print (\"Iter \" + str(i) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "            if i % 10:\n",
    "                # Calculate accuracy for 128 MNIST test images and\n",
    "                # add to summaries\n",
    "                summary, acc = sess.run([merged, accuracy],\n",
    "                                        feed_dict={_inputs: test_data,\n",
    "                                                   y: test_label})\n",
    "                test_writer.add_summary(summary, i)\n",
    "\n",
    "    test_acc = sess.run(accuracy, feed_dict={_inputs: test_data,\n",
    "                                             y: test_label})\n",
    "    print (\"Test Accuracy:\", test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n",
      "WARNING:tensorflow:From <ipython-input-12-494f03fd047f>:14: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-12-494f03fd047f>:15: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/rnn_cell_impl.py:454: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/client/session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-494f03fd047f>:14: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-12-494f03fd047f>:15: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/rnn_cell_impl.py:454: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'test'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-494f03fd047f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0msess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mv1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglobal_variables_initializer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m test_data = mnist.test.images[:batch_size].reshape((-1,\n\u001B[0m\u001B[1;32m     39\u001B[0m                                             time_steps, element_size))\n\u001B[1;32m     40\u001B[0m \u001B[0mtest_label\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmnist\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'test'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "mnist = tfds.load(name='mnist', split=['train', 'test'], data_dir=\"../data/\")\n",
    "\n",
    "element_size = 28;time_steps = 28;num_classes = 10\n",
    "batch_size = 128;hidden_layer_size = 128\n",
    "\n",
    "_inputs = tf.compat.v1.placeholder(tf.float32,shape=[None, time_steps,\n",
    "                                           element_size],\n",
    "                                           name='inputs')\n",
    "y = tf.compat.v1.placeholder(tf.float32, shape=[None, num_classes],name='inputs')\n",
    "\n",
    "# TensorFlow built-in functions\n",
    "rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_layer_size)\n",
    "outputs, _ = tf.compat.v1.nn.dynamic_rnn(rnn_cell, _inputs, dtype=tf.float32)\n",
    "\n",
    "Wl = tf.Variable(tf.compat.v1.truncated_normal([hidden_layer_size, num_classes],\n",
    "                                     mean=0,stddev=.01))\n",
    "bl = tf.Variable(tf.compat.v1.truncated_normal([num_classes],mean=0,stddev=.01))\n",
    "\n",
    "def get_linear_layer(vector):\n",
    "    return tf.matmul(vector, Wl) + bl\n",
    "\n",
    "last_rnn_output = outputs[:,-1,:]\n",
    "final_output = get_linear_layer(last_rnn_output)\n",
    "\n",
    "softmax = tf.nn.softmax_cross_entropy_with_logits(logits=final_output,\n",
    "                                                  labels=y)\n",
    "cross_entropy = tf.reduce_mean(softmax)\n",
    "train_step = tf.compat.v1.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(final_output,1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100\n",
    "\n",
    "sess=tf.compat.v1.InteractiveSession()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "test_data = mnist.test.images[:batch_size].reshape((-1,\n",
    "                                            time_steps, element_size))\n",
    "test_label = mnist.test.labels[:batch_size]\n",
    "\n",
    "for i in range(3001):\n",
    "\n",
    "       batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "       batch_x = batch_x.reshape((batch_size, time_steps, element_size))\n",
    "       sess.run(train_step,feed_dict={_inputs:batch_x,\n",
    "                                      y:batch_y})\n",
    "       if i % 1000 == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={_inputs: batch_x,\n",
    "                                                y: batch_y})\n",
    "            loss = sess.run(cross_entropy,feed_dict={_inputs:batch_x,\n",
    "                                                     y:batch_y})\n",
    "            print (\"Iter \" + str(i) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "\n",
    "print (\"Testing Accuracy:\",\n",
    "    sess.run(accuracy, feed_dict={_inputs: test_data, y: test_label}))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 128;embedding_dimension = 64;num_classes = 2\n",
    "hidden_layer_size = 32;times_steps = 6;element_size = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "digit_to_word_map = {1: \"One\", 2: \"Two\", 3: \"Three\", 4: \"Four\", 5: \"Five\", 6: \"Six\", 7: \"Seven\", 8: \"Eight\", 9: \"Nine\", 0: \"PAD\"}\n",
    "\n",
    "even_sentences = []\n",
    "odd_sentences = []\n",
    "seqlens = []\n",
    "for i in range(10000):\n",
    "    rand_seq_len = np.random.choice(range(3,7))\n",
    "    seqlens.append(rand_seq_len)\n",
    "    rand_odd_ints = np.random.choice(range(1,10,2),\n",
    "                                     rand_seq_len)\n",
    "    rand_even_ints = np.random.choice(range(2,10,2),\n",
    "                                      rand_seq_len)\n",
    "\n",
    "    # Padding\n",
    "    if rand_seq_len<6:\n",
    "        rand_odd_ints = np.append(rand_odd_ints,\n",
    "                                  [0]*(6-rand_seq_len))\n",
    "        rand_even_ints = np.append(rand_even_ints,\n",
    "                                   [0]*(6-rand_seq_len))\n",
    "\n",
    "    even_sentences.append(\" \".join([digit_to_word_map[r] for\n",
    "                               r in rand_odd_ints]))\n",
    "    odd_sentences.append(\" \".join([digit_to_word_map[r] for\n",
    "                              r in rand_even_ints]))\n",
    "\n",
    "data = even_sentences+odd_sentences\n",
    "# Same seq lengths for even, odd sentences\n",
    "seqlens*=2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['Seven Five Seven PAD PAD PAD',\n 'Nine Seven Five One Three PAD',\n 'Five One Nine PAD PAD PAD',\n 'Five Nine One One One PAD',\n 'One One Three One Five Seven',\n 'Nine One Three Seven Nine Nine']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_sentences[0:6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['Four Four Six PAD PAD PAD',\n 'Six Four Four Six Four PAD',\n 'Four Two Eight PAD PAD PAD',\n 'Eight Eight Six Eight Eight PAD',\n 'Two Eight Six Four Four Six',\n 'Eight Two Four Two Four Two']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_sentences[0:6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[3, 5, 3, 5, 6, 6]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqlens[0:6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Map from words to indices\n",
    "word2index_map ={}\n",
    "index=0\n",
    "for sent in data:\n",
    "    for word in sent.lower().split():\n",
    "        if word not in word2index_map:\n",
    "            word2index_map[word] = index\n",
    "            index+=1\n",
    "# Inverse map\n",
    "index2word_map = {index: word for word, index in word2index_map.items()}\n",
    "vocabulary_size = len(index2word_map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "labels = [1]*10000 + [0]*10000\n",
    "for i in range(len(labels)):\n",
    "    label = labels[i]\n",
    "    one_hot_encoding = [0]*2\n",
    "    one_hot_encoding[label] = 1\n",
    "    labels[i] = one_hot_encoding\n",
    "\n",
    "\n",
    "data_indices = list(range(len(data)))\n",
    "np.random.shuffle(data_indices)\n",
    "data = np.array(data)[data_indices]\n",
    "\n",
    "labels = np.array(labels)[data_indices]\n",
    "seqlens = np.array(seqlens)[data_indices]\n",
    "train_x = data[:10000]\n",
    "train_y = labels[:10000]\n",
    "train_seqlens = seqlens[:10000]\n",
    "\n",
    "test_x = data[10000:]\n",
    "test_y = labels[10000:]\n",
    "test_seqlens = seqlens[10000:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def get_sentence_batch(batch_size,data_x,\n",
    "                       data_y,data_seqlens):\n",
    "    instance_indices = list(range(len(data_x)))\n",
    "    np.random.shuffle(instance_indices)\n",
    "    batch = instance_indices[:batch_size]\n",
    "    x = [[word2index_map[word] for word in data_x[i].lower().split()]\n",
    "         for i in batch]\n",
    "    y = [data_y[i] for i in batch]\n",
    "    seqlens = [data_seqlens[i] for i in batch]\n",
    "    return x,y,seqlens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "_inputs = tf.compat.v1.placeholder(tf.int32, shape=[batch_size,times_steps])\n",
    "_labels = tf.compat.v1.placeholder(tf.float32, shape=[batch_size, num_classes])\n",
    "\n",
    "# seqlens for dynamic calculation\n",
    "_seqlens = tf.compat.v1.placeholder(tf.int32, shape=[batch_size])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "with tf.name_scope(\"embeddings\"):\n",
    "    embeddings = tf.Variable(\n",
    "        tf.compat.v1.random_uniform([vocabulary_size,\n",
    "                           embedding_dimension],\n",
    "                          -1.0, 1.0),name='embedding')\n",
    "    embed = tf.nn.embedding_lookup(embeddings, _inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'forget_bias')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-a4a38aaad53e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mv1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvariable_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"lstm\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     lstm_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_layer_size,\n\u001B[0m\u001B[1;32m      3\u001B[0m                                              forget_bias=1.0)\n\u001B[1;32m      4\u001B[0m     outputs, states = tf.compat.v1.nn.dynamic_rnn(lstm_cell, embed,\n\u001B[1;32m      5\u001B[0m                                         \u001B[0msequence_length\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_seqlens\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    322\u001B[0m               \u001B[0;34m'in a future version'\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdate\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m'after %s'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mdate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    323\u001B[0m               instructions)\n\u001B[0;32m--> 324\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    325\u001B[0m     return tf_decorator.make_decorator(\n\u001B[1;32m    326\u001B[0m         \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_func\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'deprecated'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, num_units, activation, reuse, name, dtype, **kwargs)\u001B[0m\n\u001B[1;32m    418\u001B[0m                \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    419\u001B[0m                **kwargs):\n\u001B[0;32m--> 420\u001B[0;31m     super(BasicRNNCell, self).__init__(\n\u001B[0m\u001B[1;32m    421\u001B[0m         _reuse=reuse, name=name, dtype=dtype, **kwargs)\n\u001B[1;32m    422\u001B[0m     \u001B[0m_check_supported_dtypes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, trainable, name, dtype, **kwargs)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    205\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 206\u001B[0;31m     super(RNNCell, self).__init__(\n\u001B[0m\u001B[1;32m    207\u001B[0m         trainable=trainable, name=name, dtype=dtype, **kwargs)\n\u001B[1;32m    208\u001B[0m     \u001B[0;31m# Attribute that indicates whether the cell is a TF RNN cell, due the slight\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/layers/base.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, trainable, name, dtype, **kwargs)\u001B[0m\n\u001B[1;32m    210\u001B[0m       \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'autocast'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 212\u001B[0;31m     super(Layer, self).__init__(trainable=trainable, name=name, dtype=dtype,\n\u001B[0m\u001B[1;32m    213\u001B[0m                                 **kwargs)\n\u001B[1;32m    214\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    454\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    455\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 456\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    457\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    458\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     }\n\u001B[1;32m    169\u001B[0m     \u001B[0;31m# Validate optional keyword arguments.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 170\u001B[0;31m     \u001B[0mgeneric_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidate_kwargs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallowed_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    171\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m     \u001B[0;31m# Mutable properties\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001B[0m in \u001B[0;36mvalidate_kwargs\u001B[0;34m(kwargs, allowed_kwargs, error_message)\u001B[0m\n\u001B[1;32m    790\u001B[0m   \u001B[0;32mfor\u001B[0m \u001B[0mkwarg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    791\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mkwarg\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mallowed_kwargs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 792\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror_message\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwarg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    793\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    794\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: ('Keyword argument not understood:', 'forget_bias')"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.variable_scope(\"lstm\"):\n",
    "    lstm_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_layer_size,\n",
    "                                             forget_bias=1.0)\n",
    "    outputs, states = tf.compat.v1.nn.dynamic_rnn(lstm_cell, embed,\n",
    "                                        sequence_length = _seqlens,\n",
    "                                        dtype=tf.float32)\n",
    "\n",
    "weights = {\n",
    "    'linear_layer': tf.Variable(tf.compat.v1.truncated_normal([hidden_layer_size,\n",
    "                                                     num_classes],\n",
    "                                                     mean=0,stddev=.01))\n",
    "}\n",
    "biases = {\n",
    "    'linear_layer':tf.Variable(tf.compat.v1.truncated_normal([num_classes],\n",
    "                                                   mean=0,stddev=.01))\n",
    "}\n",
    "\n",
    "# Extract the last relevant output and use in a linear layer\n",
    "final_output = tf.matmul(states[1],\n",
    "                         weights[\"linear_layer\"]) + biases[\"linear_layer\"]\n",
    "softmax = tf.nn.softmax_cross_entropy_with_logits(logits = final_output,\n",
    "                                                  labels = _labels)\n",
    "cross_entropy = tf.reduce_mean(softmax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'inputs_1' with dtype float and shape [?,28,28]\n\t [[node inputs_1 (defined at <ipython-input-12-494f03fd047f>:8) ]]\n\nOriginal stack trace for 'inputs_1':\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2866, in run_cell\n    result = self._run_cell(\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3071, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-494f03fd047f>\", line 8, in <module>\n    _inputs = tf.compat.v1.placeholder(tf.float32,shape=[None, time_steps,\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 3026, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6675, in placeholder\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3319, in _create_op_internal\n    ret = Operation(\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 1791, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_do_call\u001B[0;34m(self, fn, *args)\u001B[0m\n\u001B[1;32m   1364\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1365\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1366\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOpError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_run_fn\u001B[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[1;32m   1348\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extend_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1349\u001B[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001B[0m\u001B[1;32m   1350\u001B[0m                                       target_list, run_metadata)\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_call_tf_sessionrun\u001B[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[1;32m   1440\u001B[0m                           run_metadata):\n\u001B[0;32m-> 1441\u001B[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001B[0m\u001B[1;32m   1442\u001B[0m                                             \u001B[0mfetch_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_list\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: You must feed a value for placeholder tensor 'inputs_1' with dtype float and shape [?,28,28]\n\t [[{{node inputs_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-25-c81bf3f3fcdd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m                                                            \u001B[0mtrain_x\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtrain_y\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m                                                            train_seqlens)\n\u001B[0;32m---> 14\u001B[0;31m         sess.run(train_step,feed_dict={_inputs:x_batch, _labels:y_batch,\n\u001B[0m\u001B[1;32m     15\u001B[0m                                        _seqlens:seqlen_batch})\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m    955\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    956\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 957\u001B[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001B[0m\u001B[1;32m    958\u001B[0m                          run_metadata_ptr)\n\u001B[1;32m    959\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_run\u001B[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m   1178\u001B[0m     \u001B[0;31m# or if the call is a partial run that specifies feeds.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1179\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mfinal_fetches\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mfinal_targets\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mfeed_dict_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1180\u001B[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001B[0m\u001B[1;32m   1181\u001B[0m                              feed_dict_tensor, options, run_metadata)\n\u001B[1;32m   1182\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_do_run\u001B[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m   1356\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1357\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhandle\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1358\u001B[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001B[0m\u001B[1;32m   1359\u001B[0m                            run_metadata)\n\u001B[1;32m   1360\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_do_call\u001B[0;34m(self, fn, *args)\u001B[0m\n\u001B[1;32m   1382\u001B[0m                     \u001B[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1383\u001B[0m                     'disable_meta_optimizer = True')\n\u001B[0;32m-> 1384\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnode_def\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1385\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1386\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_extend_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: You must feed a value for placeholder tensor 'inputs_1' with dtype float and shape [?,28,28]\n\t [[node inputs_1 (defined at <ipython-input-12-494f03fd047f>:8) ]]\n\nOriginal stack trace for 'inputs_1':\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2866, in run_cell\n    result = self._run_cell(\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3071, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-494f03fd047f>\", line 8, in <module>\n    _inputs = tf.compat.v1.placeholder(tf.float32,shape=[None, time_steps,\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 3026, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6675, in placeholder\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3319, in _create_op_internal\n    ret = Operation(\n  File \"/home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 1791, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.compat.v1.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(_labels,1),\n",
    "                              tf.argmax(final_output,1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction,\n",
    "                                   tf.float32)))*100\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "    for step in range(1000):\n",
    "        x_batch, y_batch,seqlen_batch = get_sentence_batch(batch_size,\n",
    "                                                           train_x,train_y,\n",
    "                                                           train_seqlens)\n",
    "        sess.run(train_step,feed_dict={_inputs:x_batch, _labels:y_batch,\n",
    "                                       _seqlens:seqlen_batch})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            acc = sess.run(accuracy,feed_dict={_inputs:x_batch,\n",
    "                                               _labels:y_batch,\n",
    "                                               _seqlens:seqlen_batch})\n",
    "            print(\"Accuracy at %d: %.5f\" % (step, acc))\n",
    "\n",
    "    for test_batch in range(5):\n",
    "        x_test, y_test,seqlen_test = get_sentence_batch(batch_size,\n",
    "                                                        test_x,test_y,\n",
    "                                                        test_seqlens)\n",
    "        batch_pred,batch_acc = sess.run([tf.argmax(final_output,1),\n",
    "                                         accuracy],\n",
    "                                        feed_dict={_inputs:x_test,\n",
    "                                                   _labels:y_test,\n",
    "                                                   _seqlens:seqlen_test})\n",
    "        print(\"Test batch accuracy %d: %.5f\" % (test_batch, batch_acc))\n",
    "\n",
    "    output_example = sess.run([outputs],feed_dict={_inputs:x_test,\n",
    "                                                   _labels:y_test,\n",
    "                                                   _seqlens:seqlen_test})\n",
    "    states_example = sess.run([states[1]],feed_dict={_inputs:x_test,\n",
    "                                                   _labels:y_test,\n",
    "                                                   _seqlens:seqlen_test})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seqlen_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-47badba088d1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mseqlen_test\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'seqlen_test' is not defined"
     ]
    }
   ],
   "source": [
    "seqlen_test[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-27-65a6c6e92b2e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0moutput_example\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'output_example' is not defined"
     ]
    }
   ],
   "source": [
    "output_example[0][1][:6,0:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'states_example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-7bc1220871f0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mstates_example\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'states_example' is not defined"
     ]
    }
   ],
   "source": [
    "states_example[0][1][0:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-2fc932e04840>:4: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-29-2fc932e04840>:6: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-2fc932e04840>:4: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-29-2fc932e04840>:6: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "num_LSTM_layers = 2\n",
    "with tf.compat.v1.variable_scope(\"lstm\"):\n",
    "\n",
    "    lstm_cell_list = [tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_layer_size,forget_bias=1.0)\n",
    "        for ii in range(num_LSTM_layers)]\n",
    "    cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell(cells=lstm_cell_list,\n",
    "        state_is_tuple=True)\n",
    "    outputs, states = tf.compat.v1.nn.dynamic_rnn(cell, embed,\n",
    "                                        sequence_length = _seqlens,\n",
    "                                        dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-30-f2cc74c93e20>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Extract the final state and use in a linear layer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m final_output = tf.matmul(states[num_LSTM_layers-1][1],\n\u001B[0;32m----> 3\u001B[0;31m                          weights[\"linear_layer\"]) + biases[\"linear_layer\"]\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract the final state and use in a linear layer\n",
    "final_output = tf.matmul(states[num_LSTM_layers-1][1],\n",
    "                         weights[\"linear_layer\"]) + biases[\"linear_layer\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
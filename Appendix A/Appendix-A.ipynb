{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-c236d1e509eb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0msess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minit\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mNUM_STEPS\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m             \u001B[0msess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mx_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0my_data\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mstep\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;36m5\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "NUM_STEPS = 10\n",
    "\n",
    "g = tf.Graph()\n",
    "wb_ = []\n",
    "with g.as_default():\n",
    "    x = tf.compat.v1.placeholder(tf.float32,shape=[None,3])\n",
    "    y_true = tf.compat.v1.placeholder(tf.float32,shape=None)\n",
    "\n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0,0,0]],dtype=tf.float32,name='weights')\n",
    "        b = tf.Variable(0,dtype=tf.float32,name='bias')\n",
    "        y_pred = tf.matmul(w,tf.transpose(x)) + b\n",
    "\n",
    "    with tf.name_scope('loss') as scope:\n",
    "        loss = tf.reduce_mean(tf.square(y_true-y_pred))\n",
    "\n",
    "    with tf.name_scope('train') as scope:\n",
    "        learning_rate = 0.5\n",
    "        optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)\n",
    "        train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(NUM_STEPS):\n",
    "            sess.run(train,{x: x_data, y_true: y_data})\n",
    "            if step % 5 == 0:\n",
    "                print(step, sess.run([w,b]))\n",
    "                wb_.append(sess.run([w,b]))\n",
    "\n",
    "        print(10, sess.run([w,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-37c075316719>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m \u001B[0mrun_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m \u001B[0mrun_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "def predict(x,y_true,w,b):\n",
    "    y_pred = tf.matmul(w,tf.transpose(x)) + b\n",
    "    return y_pred\n",
    "\n",
    "def get_loss(y_pred,y_true):\n",
    "    loss = tf.reduce_mean(tf.square(y_true-y_pred))\n",
    "    return loss\n",
    "\n",
    "def get_optimizer(y_pred,y_true):\n",
    "    loss = get_loss(y_pred,y_true)\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(0.5)\n",
    "    train = optimizer.minimize(loss)\n",
    "    return train\n",
    "\n",
    "def run_model(x_data,y_data):\n",
    "        wb_ = []\n",
    "        # Define placeholders and variables\n",
    "        x = tf.compat.v1.placeholder(tf.float32,shape=[None,3])\n",
    "        y_true = tf.compat.v1.placeholder(tf.float32,shape=None)\n",
    "        w = tf.Variable([[0,0,0]],dtype=tf.float32)\n",
    "        b = tf.Variable(0,dtype=tf.float32)\n",
    "        print(b.name)\n",
    "\n",
    "        # Form predictions\n",
    "        y_pred = predict(x,y_true,w,b)\n",
    "\n",
    "        # Create optimizer\n",
    "        train = get_optimizer(y_pred,y_data)\n",
    "\n",
    "        # Run session\n",
    "        init = tf.compat.v1.global_variables_initializer()\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            sess.run(init)\n",
    "            for step in range(10):\n",
    "                sess.run(train,{x: x_data, y_true: y_data})\n",
    "                if step % 5 == 0:\n",
    "                    print(step, sess.run([w,b]))\n",
    "                    wb_.append(sess.run([w,b]))\n",
    "\n",
    "\n",
    "run_model(x_data,y_data)\n",
    "run_model(x_data,y_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "w = tf.compat.v1.get_variable('w',[1,3],initializer=tf.zeros_initializer())\n",
    "b = tf.compat.v1.get_variable('b',[1,1],initializer=tf.zeros_initializer())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-94b9fbfb9a55>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mv1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvariable_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Regression\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mscope\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m     \u001B[0mrun_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m     \u001B[0mscope\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreuse_variables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0mrun_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "def run_model(x_data,y_data):\n",
    "        wb_ = []\n",
    "        # Define placeholders and variables\n",
    "        x = tf.compat.v1.placeholder(tf.float32,shape=[None,3])\n",
    "        y_true = tf.compat.v1.placeholder(tf.float32,shape=None)\n",
    "\n",
    "        w = tf.compat.v1.get_variable('w',[1,3],initializer=tf.zeros_initializer())\n",
    "        b = tf.compat.v1.get_variable('b',[1,1],initializer=tf.zeros_initializer())\n",
    "\n",
    "        print(b.name,w.name)\n",
    "\n",
    "        # Form predictions\n",
    "        y_pred = predict(x,y_true,w,b)\n",
    "\n",
    "        # Create optimizer\n",
    "        train = get_optimizer(y_pred,y_data)\n",
    "\n",
    "        # Run session\n",
    "        init = tf.compat.v1.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        for step in range(10):\n",
    "            sess.run(train,{x: x_data, y_true: y_data})\n",
    "            if (step % 5 == 4) or (step == 0):\n",
    "                print(step, sess.run([w,b]))\n",
    "                wb_.append(sess.run([w,b]))\n",
    "\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "with tf.compat.v1.variable_scope(\"Regression\") as scope:\n",
    "    run_model(x_data,y_data)\n",
    "    scope.reuse_variables()\n",
    "    run_model(x_data,y_data)\n",
    "sess.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-73c14e2fbb61>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0mlin_reg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m \u001B[0mlin_reg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m \u001B[0mlin_reg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "\n",
    "        # Model\n",
    "        self.x = tf.compat.v1.placeholder(tf.float32,shape=[None,3])\n",
    "        self.y_true = tf.compat.v1.placeholder(tf.float32,shape=None)\n",
    "        self.w = tf.Variable([[0,0,0]],dtype=tf.float32)\n",
    "        self.b = tf.Variable(0,dtype=tf.float32)\n",
    "\n",
    "        init = tf.compat.v1.global_variables_initializer()\n",
    "        self.sess = tf.compat.v1.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "        self._output = None\n",
    "        self._optimizer = None\n",
    "        self._loss = None\n",
    "\n",
    "    def fit(self,x_data,y_data):\n",
    "        print(self.b.name)\n",
    "\n",
    "        for step in range(10):\n",
    "            self.sess.run(self.optimizer,{self.x: x_data, self.y_true: y_data})\n",
    "            if (step % 5 == 4) or (step == 0):\n",
    "                print(step, self.sess.run([self.w,self.b]))\n",
    "\n",
    "\n",
    "    @property\n",
    "    def output(self):\n",
    "        if not self._output:\n",
    "            y_pred = tf.matmul(self.w,tf.transpose(self.x)) + self.b\n",
    "            self._output = y_pred\n",
    "        return self._output\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        if not self._loss:\n",
    "            error = tf.reduce_mean(tf.square(self.y_true-self.output))\n",
    "            self._loss= error\n",
    "        return self._loss\n",
    "\n",
    "    @property\n",
    "    def optimizer(self):\n",
    "        if not self._optimizer:\n",
    "            opt = tf.compat.v1.train.GradientDescentOptimizer(0.5)\n",
    "            opt = opt.minimize(self.loss)\n",
    "            self._optimizer = opt\n",
    "        return self._optimizer\n",
    "\n",
    "\n",
    "lin_reg = Model()\n",
    "lin_reg.fit(x_data,y_data)\n",
    "lin_reg.fit(x_data,y_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-c93b8b842b4a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[0mlin_reg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m \u001B[0mlin_reg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0mMSE\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlin_reg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMSE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "\n",
    "        # Model\n",
    "        self.x = tf.compat.v1.placeholder(tf.float32,shape=[None,3])\n",
    "        self.y_true = tf.compat.v1.placeholder(tf.float32,shape=None)\n",
    "\n",
    "        self.params = self._initialize_weights()\n",
    "\n",
    "        init = tf.compat.v1.global_variables_initializer()\n",
    "        self.sess = tf.compat.v1.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "        self.output\n",
    "        self.optimizer\n",
    "        self.loss\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        params = dict()\n",
    "        params['w'] = tf.Variable([[0,0,0]],dtype=tf.float32)\n",
    "        params['b'] = tf.Variable(0,dtype=tf.float32)\n",
    "        return params\n",
    "\n",
    "    def fit(self,x_data,y_data):\n",
    "        print(self.params['b'].name)\n",
    "\n",
    "        for step in range(10):\n",
    "            self.sess.run(self.optimizer,{self.x: x_data, self.y_true: y_data})\n",
    "            if (step % 5 == 4) or (step == 0):\n",
    "                print(step,\n",
    "                 self.sess.run([self.params['w'],self.params['b']]))\n",
    "\n",
    "    def evaluate(self,x_data,y_data):\n",
    "        print(self.params['b'].name)\n",
    "\n",
    "        MSE = self.sess.run(self.loss,{self.x: x_data, self.y_true: y_data})\n",
    "        return MSE\n",
    "\n",
    "    def getWeights(self):\n",
    "        return self.sess.run([self.params['b']])\n",
    "\n",
    "\n",
    "    @property_with_check\n",
    "    def output(self):\n",
    "        y_pred = tf.matmul(self.params['w'],tf.transpose(self.x)) + \\\n",
    "            self.params['b']\n",
    "        return y_pred\n",
    "\n",
    "    @property_with_check\n",
    "    def loss(self):\n",
    "        error = tf.reduce_mean(tf.square(self.y_true-self.output))\n",
    "        return error\n",
    "\n",
    "    @property_with_check\n",
    "    def optimizer(self):\n",
    "        opt = tf.compat.v1.train.GradientDescentOptimizer(0.5)\n",
    "        opt = opt.minimize(self.loss)\n",
    "        return opt\n",
    "\n",
    "\n",
    "lin_reg = Model()\n",
    "lin_reg.fit(x_data,y_data)\n",
    "MSE = lin_reg.evaluate(x_data,y_data)\n",
    "print(MSE)\n",
    "\n",
    "print(lin_reg.getWeights())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def property_with_check(input_fn):\n",
    "    attribute = '_cache_' + input_fn.__name__\n",
    "\n",
    "    @property\n",
    "    @functools.wraps(input_fn)\n",
    "    def check_attr(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            setattr(self, attribute, input_fn(self))\n",
    "        return getattr(self, attribute)\n",
    "\n",
    "    return check_attr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"Const:0\", shape=(1,), dtype=int32) must be from the same graph as Tensor(\"softmax_cross_entropy_with_logits/Reshape_2:0\", shape=(1,), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-c40005ffff84>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m cross_entropy = tf.reduce_mean(\n\u001B[0m\u001B[1;32m      2\u001B[0m         tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36mreduce_mean\u001B[0;34m(input_tensor, axis, keepdims, name)\u001B[0m\n\u001B[1;32m   2062\u001B[0m   return _may_reduce_to_scalar(\n\u001B[1;32m   2063\u001B[0m       \u001B[0mkeepdims\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2064\u001B[0;31m       gen_math_ops.mean(\n\u001B[0m\u001B[1;32m   2065\u001B[0m           \u001B[0minput_tensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_ReductionDims\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_tensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2066\u001B[0m           name=name))\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001B[0m in \u001B[0;36mmean\u001B[0;34m(input, axis, keep_dims, name)\u001B[0m\n\u001B[1;32m   5812\u001B[0m     \u001B[0mkeep_dims\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5813\u001B[0m   \u001B[0mkeep_dims\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_execute\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmake_bool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeep_dims\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"keep_dims\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5814\u001B[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001B[0m\u001B[1;32m   5815\u001B[0m         \u001B[0;34m\"Mean\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction_indices\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeep_dims\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkeep_dims\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5816\u001B[0m                 name=name)\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001B[0m in \u001B[0;36m_apply_op_helper\u001B[0;34m(op_type_name, name, **keywords)\u001B[0m\n\u001B[1;32m    307\u001B[0m     \u001B[0;31m# Need to flatten all the arguments into a list.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    308\u001B[0m     \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 309\u001B[0;31m     \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_graph_from_inputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_Flatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeywords\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    310\u001B[0m     \u001B[0;31m# pylint: enable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    311\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mAssertionError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36m_get_graph_from_inputs\u001B[0;34m(op_input_list, graph)\u001B[0m\n\u001B[1;32m   5919\u001B[0m         \u001B[0mgraph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_element\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgraph\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5920\u001B[0m       \u001B[0;32melif\u001B[0m \u001B[0moriginal_graph_element\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5921\u001B[0;31m         \u001B[0m_assert_same_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moriginal_graph_element\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgraph_element\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5922\u001B[0m       \u001B[0;32melif\u001B[0m \u001B[0mgraph_element\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgraph\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mgraph\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5923\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"%s is not from the passed-in graph.\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mgraph_element\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36m_assert_same_graph\u001B[0;34m(original_item, item)\u001B[0m\n\u001B[1;32m   5853\u001B[0m   \"\"\"\n\u001B[1;32m   5854\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0moriginal_item\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgraph\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgraph\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5855\u001B[0;31m     raise ValueError(\"%s must be from the same graph as %s.\" %\n\u001B[0m\u001B[1;32m   5856\u001B[0m                      (item, original_item))\n\u001B[1;32m   5857\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Tensor(\"Const:0\", shape=(1,), dtype=int32) must be from the same graph as Tensor(\"softmax_cross_entropy_with_logits/Reshape_2:0\", shape=(1,), dtype=float32)."
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y_true-y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-16c5ebec4d01>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-11-16c5ebec4d01>\"\u001B[0;36m, line \u001B[0;32m1\u001B[0m\n\u001B[0;31m    def my_loss_function(key-variables...):\u001B[0m\n\u001B[0m                            ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def my_loss_function(key-variables...):\n",
    "    loss = ...\n",
    "    return loss\n",
    "\n",
    "\n",
    "my_loss = my_loss_function(key-variables...)\n",
    "gd_step = tf.train.GradientDescentOptimizer().minimize(my_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LAMBDA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-11ee59b843a8>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m         tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0mtotal_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcross_entropy\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mLAMBDA\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0ml2_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mW\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0mgd_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGradientDescentOptimizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mminimize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtotal_loss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'LAMBDA' is not defined"
     ]
    }
   ],
   "source": [
    "x = tf.compat.v1.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "\n",
    "y_true = tf.compat.v1.placeholder(tf.float32, [None, 10])\n",
    "y_pred = tf.matmul(x, W)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "\n",
    "total_loss = cross_entropy + LAMBDA * tf.nn.l2_loss(W)\n",
    "\n",
    "gd_step = tf.train.GradientDescentOptimizer(0.5).minimize(total_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "LAMBDA = 1e-5\n",
    "\n",
    "def mul_lambda(val):\n",
    "    return np.multiply(val, LAMBDA).astype(np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'py_func'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-b302b29fa9d7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpy_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmy_python_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0moutput_types\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'py_func'"
     ]
    }
   ],
   "source": [
    "tf.py_func(my_python_function, [input], [output_types])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'py_func'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-57059fbd7c3c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtotal_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcross_entropy\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m         \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpy_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmul_lambda\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0ml2_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mW\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'py_func'"
     ]
    }
   ],
   "source": [
    "total_loss = cross_entropy + \\\n",
    "        tf.py_func(mul_lambda, [tf.nn.l2_loss(W)], [tf.float32])[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "@tf.RegisterGradient(\"PyMulLambda\")\n",
    "def grad_mul_lambda(op, grad):\n",
    "    return LAMBDA*grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'py_func'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-19-69ed4ae4cc16>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mv1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_default_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient_override_map\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"PyFunc\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"PyMulLambda\"\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mtotal_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcross_entropy\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m             \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpy_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmul_lambda\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0ml2_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mW\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'py_func'"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.get_default_graph().gradient_override_map({\"PyFunc\": \"PyMulLambda\"}):\n",
    "    total_loss = cross_entropy + \\\n",
    "            tf.py_func(mul_lambda, [tf.nn.l2_loss(W)], [tf.float32])[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Registering two gradient with name 'PyMulLambda'! (Previous registration was in register /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/registry.py:66)\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-ef1cad75c5b4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m@\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRegisterGradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"PyMulLambda\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0;32mdef\u001B[0m \u001B[0mgrad_mul_lambda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mLAMBDA\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, f)\u001B[0m\n\u001B[1;32m   2438\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2439\u001B[0m     \u001B[0;34m\"\"\"Registers the function `f` as gradient function for `op_type`.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2440\u001B[0;31m     \u001B[0m_gradient_registry\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mregister\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_op_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2441\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2442\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/registry.py\u001B[0m in \u001B[0;36mregister\u001B[0;34m(self, candidate, name)\u001B[0m\n\u001B[1;32m     56\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_registry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m       \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_registry\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0m_LOCATION_TAG\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m       raise KeyError(\n\u001B[0m\u001B[1;32m     59\u001B[0m           \u001B[0;34m\"Registering two %s with name '%s'! \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m           \u001B[0;34m\"(Previous registration was in %s %s:%d)\"\u001B[0m \u001B[0;34m%\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Registering two gradient with name 'PyMulLambda'! (Previous registration was in register /home/af/Dokumenter/Programs/miniconda3/envs/LearningTensorFlow/lib/python3.8/site-packages/tensorflow/python/framework/registry.py:66)\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "LAMBDA = 1e-5\n",
    "\n",
    "def mul_lambda(val):\n",
    "    return np.multiply(val, LAMBDA).astype(np.float32)\n",
    "\n",
    "\n",
    "@tf.RegisterGradient(\"PyMulLambda\")\n",
    "def grad_mul_lambda(op, grad):\n",
    "    return LAMBDA*grad\n",
    "\n",
    "\n",
    "x = tf.compat.v1.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "\n",
    "y_true = tf.compat.v1.placeholder(tf.float32, [None, 10])\n",
    "y_pred = tf.matmul(x, W)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\\\n",
    "                (logits=y_pred, labels=y_true))\n",
    "\n",
    "with tf.compat.v1.get_default_graph().gradient_override_map({\"PyFunc\": \"PyMulLambda\"}):\n",
    "    total_loss = cross_entropy + \\\n",
    "            tf.compat.v1.py_func(mul_lambda, [tf.nn.l2_loss(W)], [tf.float32])[0]\n",
    "\n",
    "gd_step = tf.compat.v1.train.GradientDescentOptimizer(0.5).minimize(total_loss)\n",
    "\n",
    "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}